# -*- coding: utf-8 -*-
import scrapy
import re
from scrapy.linkextractors import LinkExtractor
from scrapy.spiders import CrawlSpider, Rule
from scrapy import Request
from news2.items import News2Item
from news2.settings import PRESSPROJECT_VARS

class DogSpider(CrawlSpider):
    name = 'pressproject'
    allowed_domains = ['thepressproject.gr']
    start_urls = ['https://www.thepressproject.gr/']

    rules = (
        Rule(LinkExtractor(allow=('thepressproject'), deny=('binteo','videos','gallery','eikones','twit')), callback='parse_thepressproject', follow=True), 
        )

    def parse_thepressproject(self,response):
        sub = response.xpath('//div[@class="article-categories"]/a/text()').get()
        if sub == "Πολιτισμός":
            title = response.xpath('//h1[@class="entry-title"]/text()|//h1[@class="entry-title"]/*/text()').get()
            video_article = response.xpath('//i[@class="title-icon video-icon fab fa-youtube"]').get()
            if video_article is None:
                list_to_string = " ".join(" ".join(title))
                no_whites = re.sub(r'\t|\n',"",list_to_string)
                markspaces = re.sub( "       ", "space",no_whites)
                uneeded_spaces = re.sub( " ", "",markspaces)
                final_title = re.sub( "space", " ",uneeded_spaces)
                delete_front_space = re.sub("    ","",final_title)
                final_title = re.sub("   ","",delete_front_space)

                text = response.xpath('//div[@id="maintext"]//p/text()|//div[@id="maintext"]//strong/text()|//div[@id="maintext"]//p/*/text()').getall()
                list_to_string = " ".join(" ".join(text))
                markspaces = re.sub( "  ", "space",list_to_string)
                uneeded_spaces = re.sub( " ", "",markspaces)
                final_text = re.sub( "space", " ",uneeded_spaces)
                clear_characters = re.sub( "\xa0","",final_text)

                #flag to see later on if we have tweets ect
                flag = re.search(r"@",clear_characters)
                url = response.url
                date = response.xpath('//div[@class="article-date"]/label[1]/text()').get()

                #check if we are in an article, and if it doesn't have images
                if title is not None and len(clear_characters)>10 and flag is None:
                    yield {
                        "subtopic": "Culture",
                        "website": PRESSPROJECT_VARS['AUTHOR'],
                        "title": final_title,
                        "date": date, 
                        "author": PRESSPROJECT_VARS['AUTHOR'],
                        "text": re.sub( r'\s\s\s',"",clear_characters),
                        "url": url,                
                    }
